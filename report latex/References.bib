@misc{arachmadi,
author = {Rachmadi,Reza F. and Uchimura,Keiichi and Komokata,Yoshinori},
year={2016},
month={Jan 01,},
title={Japan road sign classification using cascade convolutional neural network},
journal={23 rd ITS World Congress},
pages={10},
language={English},
url={https://explore.openaire.eu/search/publication?articleId=datacite\_\_\_\_::203929aafebe8a9e65d676b893571658},
}

@misc{rachmadi1,
author={Rachmadi,Reza F. and Rachmadi,Reza F. and Uchimura,Keiichi and Koutaki,Gou},
year={1725},
month={20-03},
title={Road Sign Classification using Spatial Pyramid Convolutional Neural Network Campus Grid and Render Farm View project Face analysis View project ROAD SIGN CLASSIFICATION USING SPATIAL PYRAMID CONVOLUTIONAL NEURAL NETWORK},
abstract={The road sign classification system is a very important task for a lot of intelligent transportation system (ITS) applications , including autonomous car, and road/traffic flow mapping. In this paper, we proposed a spatial pyramid convolu-tional neural network classifier for road sign classification problem. To provide a detail image structure, two-level of spatial pyramid configuration is used as input to the classi-fier. The spatial pyramid CNN classifier is built on the top of AlexNet CNN architecture. Our spatial pyramid CNN clas-sifier consists of five streams and each stream is built from convolution layer of AlexNet CNN architecture. At the end of the classifier, we use the fully-connected part of AlexNet to classify the final classification result. As a result, our experiments show that the average accuracy of the classifier is 99.6% and it outperforms our previous approach on Japan image road sign dataset.},
}

@article{bouti,
author={Bouti,Amal and Mahraz,Med A. and Riffi,Jamal and Tairi,Hamid},
year={2020},
month={May},
title={A robust system for road sign detection and classification using LeNet architecture based on convolutional neural network},
journal={Soft computing (Berlin, Germany)},
volume={24},
number={9},
pages={6721-6733},
abstract={In this paper, we are reporting a system for detection and classification of road signs. This system consists of two parts. The first part detects the road signs in real time. The second part classifies the German traffic signs (GTSRB) dataset and makes the prediction using the road signs detected in the first part to test the effectiveness. We used HOG and SVM in the detection part to detect the road signs captured by the camera. Then we used a convolutional neural network based on the LeNet model in which some modifications were added in the classification part. Our system obtains an accuracy rate of 96.85% in the detection part and 96.23% in the classification part.},
isbn={1432-7643},
language={English},
url={https://search.proquest.com/docview/2386057791},
}

@article{Alghmgham,
author={Alghmgham,Danyah A. and Latif,Ghazanfar and Alghazo,Jaafar and Alzubaidi,Loay},
year={2019},
title={Autonomous Traffic Sign (ATSR) Detection and Recognition using Deep CNN},
journal={Procedia computer science},
volume={163},
pages={266-274},
abstract={Automatic detection and recognition of traffic signs is very important and could potentially be used for driver assistance to reduce accidents and eventually in driverless automobiles. In this paper, Deep Convolutional Neural Network (CNN) is used to develop an Autonomous Traffic and Road Sign (ATRS) detection and recognition system. The proposed system works in real time detecting and recognizing traffic sign images. The contribution of this paper is also a newly developed database of 24 different traffic signs collected from random road sides in Saudi Arabia. The images were taken from different angles and including other parameters and conditions. A total of 2718 images were collected to form the database which we named Saudi Arabian Traffic and Road Signs (SA-TRS-2018). The CNN architecture was used with varying parameters in order to achieve the best recognition rates. Experimental results show that the proposed CNN architecture achieved an accuracy of 100%, thus higher than those achieved in similar previous studies.},
isbn={1877-0509},
language={English},
url={http://dx.doi.org/10.1016/j.procs.2019.12.108},
}

@article{shao,
author={Shao,Faming and Wang,Xinqing and Meng,Fanjie and Zhu,Jingwei and Wang,Dong and Dai,Juying},
year={2019},
month={May 17,},
title={Improved Faster R-CNN Traffic Sign Detection Based on a Second Region of Interest and Highly Possible Regions Proposal Network},
journal={Sensors (Basel, Switzerland)},
volume={19},
number={10},
pages={2288},
abstract={Traffic sign detection systems provide important road control information for unmanned driving systems or auxiliary driving. In this paper, the Faster region with a convolutional neural network (R-CNN) for traffic sign detection in real traffic situations has been systematically improved. First, a first step region proposal algorithm based on simplified Gabor wavelets (SGWs) and maximally stable extremal regions (MSERs) is proposed. In this way, the region proposal a priori information is obtained and will be used for improving the Faster R-CNN. This part of our method is named as the highly possible regions proposal network (HP-RPN). Second, in order to solve the problem that the Faster R-CNN cannot effectively detect small targets, a method that combines the features of the third, fourth, and fifth layers of VGG16 to enrich the features of small targets is proposed. Third, the secondary region of interest method to enhance the feature of detection objects and improve the classification capability of the Faster R-CNN is proposed. Finally, a method of merging the German traffic sign detection benchmark (GTSDB) and Chinese traffic sign dataset (CTSD) databases into one larger database to increase the number of database samples is proposed. Experimental results show that our method improves the detection performance, especially for small targets.},
isbn={1424-8220},
language={English},
url={https://www.ncbi.nlm.nih.gov/pubmed/31108980},
}

@inproceedings{rongqiang,
author={Rongqiang Qian and Qianyu Liu and Yong Yue and Coenen,Frans and Bailing Zhang},
editor={ },
year={Aug 2016},
title={Road surface traffic sign detection with hybrid region proposal and fast R-CNN},
publisher={IEEE},
pages={555-559},
abstract={Detection of traffic signs plays an important role in autonomous driving, traffic surveillance and traffic safety. Previous research in Traffic Sign Detection (TSD) generally focused on traffic signs which are over the roads, the traffic signs on road surface have not been discussed. In this paper, we propose a road surface traffic sign detection system by applying convolutional neural network (CNN). The proposed system consists of two main stages: 1) a hybrid region proposal method to hypothesize the traffic sign locations by taking into account complementary information of color and edge; 2) feature extraction, classification, bounding box regression and non-maximum suppression by Fast R-CNN. Extensive experiments have been conducted using our field-captured dataset, demonstrating outstanding performance with regard to high recall and precision rate. The overall average precision (AP) is about 85.58%.},
language={English},
url={https://ieeexplore.ieee.org/document/7603233},
}

@INPROCEEDINGS{Classification1,
author={Mehta, Smit and Paunwala, Chirag and Vaidya, Bhaumik},
booktitle={2019 International Conference on Intelligent Computing and Control Systems (ICCS)}, 
title={CNN based Traffic Sign Classification using Adam Optimizer}, 
year={2019},
volume={},
number={},
pages={1293-1298},
doi={10.1109/ICCS45141.2019.9065537}}

@article{Classification2,
author={Zhang,Jianming and Wang,Wei and Lu,Chaoquan and Wang,Jin and Sangaiah,Arun K.},
year={2020},
month={Aug},
title={Lightweight deep network for traffic sign classification},
journal={Annales des télécommunications},
volume={75},
number={7-8},
pages={369-379},
abstract={Deeper neural networks have achieved great results in the field of computer vision and have been successfully applied to tasks such as traffic sign recognition. However, as traffic sign recognition systems are often deployed in resource-constrained environments, it is critical for the network design to be slim and accurate in these instances. Accordingly, in this paper, we propose two novel lightweight networks that can obtain higher recognition precision while preserving less trainable parameters in the models. Knowledge distillation transfers the knowledge in a trained model, called the teacher network, to a smaller model, called the student network. Moreover, to improve the accuracy of traffic sign recognition, we also implement a new module in our teacher network that combines two streams of feature channels with dense connectivity. To enable easy deployment on mobile devices, our student network is a simple end-to-end architecture containing five convolutional layers and a fully connected layer. Furthermore, by referring to the values of batch normalization (BN) scaling factors towards zero to identify insignificant channels, we prune redundant channels from the student network, yielding a compact model with accuracy comparable to that of more complex models. Our teacher network exhibited an accuracy rate of 93.16% when trained and tested on the CIFAR-10 general dataset. Using the knowledge of our teacher network, we train the student network on the GTSRB and BTSC traffic sign datasets. Thus, our student model uses only 0.8 million parameters while still achieving accuracy of 99.61% and 99.13% respectively on both datasets. All experimental results show that our lightweight networks can be useful when deploying deep convolutional neural networks (CNNs) on mobile embedded devices.},
isbn={0003-4347},
language={English},
url={https://search.proquest.com/docview/2431252962},
}

@inproceedings{Classification3,
author={S. Mehta and C. Paunwala and B. Vaidya},
editor={ },
year={2019},
title={CNN based Traffic Sign Classification using Adam Optimizer},
booktitle={- 2019 International Conference on Intelligent Computing and Control Systems (ICCS)},
pages={1293-1298},
note={ID: 1},
isbn={NULL-},
}

@inproceedings{Classification4,
author={Ciresan,D. and Meier,U. and Masci,J. and Schmidhuber,J.},
editor={ },
year={Jul 2011},
title={A committee of neural networks for traffic sign classification},
publisher={IEEE},
pages={1918-1921},
abstract={We describe the approach that won the preliminary phase of the German traffic sign recognition benchmark with a better-than-human recognition rate of 98.98%.We obtain an even better recognition rate of 99.15% by further training the nets. Our fast, fully parameterizable GPU implementation of a Convolutional Neural Network does not require careful design of pre-wired feature extractors, which are rather learned in a supervised way. A CNN/MLP committee further boosts recognition performance.},
isbn={2161-4393},
language={English},
url={https://ieeexplore.ieee.org/document/6033458},
}

@article{Classification5,
author={Haloi,Mrinal},
year={2015},
month={Nov 10,},
title={Traffic Sign Classification Using Deep Inception Based Convolutional Networks},
abstract={In this work, we propose a novel deep network for traffic sign classification
that achieves outstanding performance on GTSRB surpassing all previous methods.
Our deep network consists of spatial transformer layers and a modified version
of inception module specifically designed for capturing local and global
features together. This features adoption allows our network to classify
precisely intraclass samples even under deformations. Use of spatial
transformer layer makes this network more robust to deformations such as
translation, rotation, scaling of input images. Unlike existing approaches that
are developed with hand-crafted features, multiple deep networks with huge
parameters and data augmentations, our method addresses the concern of
exploding parameters and augmentations. We have achieved the state-of-the-art
performance of 99.81\% on GTSRB dataset.},
language={English},
url={https://arxiv.org/abs/1511.02992},
}

@article{Recognition1,
author={Bouti,Amal and Mahraz,Med A. and Riffi,Jamal and Tairi,Hamid},
year={2020},
month={May},
title={A robust system for road sign detection and classification using LeNet architecture based on convolutional neural network},
journal={Soft computing (Berlin, Germany)},
volume={24},
number={9},
pages={6721-6733},
abstract={In this paper, we are reporting a system for detection and classification of road signs. This system consists of two parts. The first part detects the road signs in real time. The second part classifies the German traffic signs (GTSRB) dataset and makes the prediction using the road signs detected in the first part to test the effectiveness. We used HOG and SVM in the detection part to detect the road signs captured by the camera. Then we used a convolutional neural network based on the LeNet model in which some modifications were added in the classification part. Our system obtains an accuracy rate of 96.85% in the detection part and 96.23% in the classification part.},
isbn={1432-7643},
language={English},
url={https://search.proquest.com/docview/2386057791},
}

@article{Shustanov,
author={Shustanov,Alexander and Yakimov,Pavel},
year={2017},
title={CNN Design for Real-Time Traffic Sign Recognition},
journal={Procedia Engineering},
volume={201},
pages={718-725},
note={ID: 278653},
abstract={Nowadays, more and more object recognition tasks are being solved with Convolutional Neural Networks (CNN). Due to its high recognition rate and fast execution, the convolutional neural networks have enhanced most of computer vision tasks, both existing and new ones. In this article, we propose an implementation of traffic signs recognition algorithm using a convolution neural network. The paper also shows several CNN architectures, which are compared to each other. Training of the neural network is implemented using the TensorFlow library and massively parallel architecture for multithreaded programming CUDA. The entire procedure for traffic sign detection and recognition is executed in real time on a mobile GPU. The experimental results confirmed high efficiency of the developed computer vision system.},
isbn={1877-7058},
url={https://www.sciencedirect.com/science/article/pii/S1877705817341231},
}